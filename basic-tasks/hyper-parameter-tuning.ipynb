{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "As hyper-parameters are not trainable parameters, there are different search-based algorithms for it. The basic idea is to create combination of parameter values and assess the relative performance. Some popular ones are:\n",
    "\n",
    "1. Grid search (an exhaustive search in the parameter space)\n",
    "2. Random search (a random search in the parameter space)\n",
    "3. Bayesian Optimization\n",
    "4. Evolutionary Algorithms \n",
    "5. Gradient-based optimization\n",
    "6. Keras' Tuner\n",
    "7. Population-based optimization\n",
    "8. ParamILS \n",
    "\n",
    "[*Source here*](https://analyticsindiamag.com/top-8-approaches-for-tuning-hyperparameters-of-machine-learning-models/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1 Grid search & #2 Random Search\n",
    "\n",
    "[*Some theories*](https://medium.com/@cjl2fv/an-intro-to-hyper-parameter-optimization-using-grid-search-and-random-search-d73b9834ca0a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our estimator and parameter space**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = RandomForestRegressor(random_state=0) # we can reuse this object as the fit method returns a new estimator object with trained parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search\n",
    "Next we create a GridSearchCV object with does a grid-search with cross-validation.\n",
    "Our regressor have two hyperparamenters: n_estimators, and max_features. We create a grid with discrete values on each dimension (hyperparameter).\n",
    "We are using R<sup>2</sup> score which represents the proportion of variance of the output that has been explained by the model. More about R<sup>2</sup> [here](https://scikit-learn.org/stable/modules/model_evaluation.html#r2-score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 342 candidates, totalling 1710 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 656 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 1656 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=-1)]: Done 1710 out of 1710 | elapsed:   14.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(random_state=0), n_jobs=-1,\n",
       "             param_grid={'max_features': array([0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 ,\n",
       "       0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95]),\n",
       "                         'n_estimators': array([ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,\n",
       "       90, 95])},\n",
       "             scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {\n",
    "        'n_estimators': np.arange(5, 100, 5), \n",
    "        'max_features': np.arange(0.1, 1.0, 0.05)\n",
    "    }\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = param_grid,\n",
    "    cv = 5,\n",
    "    scoring = 'r2',\n",
    "    verbose = 1,\n",
    "    n_jobs = -1 # use all processors\n",
    ")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 0.5000000000000001, 'n_estimators': 90}\n",
      "0.4153440140065655\n"
     ]
    }
   ],
   "source": [
    "# grid_search.cv_results_\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "Here we create parameter distributions with a list which results in a uniform distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:    2.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=0),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'max_features': array([0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 , 0.55, 0.6 ,\n",
       "       0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95]),\n",
       "                                        'n_estimators': array([ 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,\n",
       "       90, 95])},\n",
       "                   random_state=0, scoring='r2', verbose=1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distributions = {\n",
    "        'n_estimators': np.arange(5, 100, 5), \n",
    "        'max_features': np.arange(0.1, 1.0, 0.05)\n",
    "    }\n",
    "rand_search = RandomizedSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_distributions = param_distributions,\n",
    "    cv = 5,\n",
    "    scoring = 'r2',\n",
    "    verbose = 1,\n",
    "    n_jobs = -1,\n",
    "    n_iter=50, # we are going to sample 50 times only.\n",
    "    random_state=0\n",
    ")\n",
    "rand_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
